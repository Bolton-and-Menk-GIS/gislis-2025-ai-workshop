import{b as r,o as l,w as i,g as e,af as t,v as u,x as m,X as s}from"./modules/vue-BuL0xg91.js";import{_ as p}from"./default.vue_vue_type_style_index_0_lang-C_FYlQgg.js";import{x as d,a6 as _}from"./index-4lMyux5v.js";import"./monaco/bundled-types-BuXtdBa6.js";import"./modules/file-saver-BzOOqXCn.js";import"./BrandLogo-BRLSAWkw.js";import"./modules/shiki-_fi6NckE.js";const C={__name:"large_language_models.md__slidev_16",setup(c){const{$clicksContext:n,$frontmatter:a}=d();return n.setup(),(f,o)=>(l(),r(p,u(m(s(_)(s(a),15))),{default:i(()=>o[0]||(o[0]=[e("h2",null,"ðŸ¤” So Whatâ€™s Happening When You Chat With an LLM?",-1),e("p",null,"Every time you send a message:",-1),e("ol",null,[e("li",null,[t("Your input is "),e("strong",null,"tokenized"),t(" into numbers.")]),e("li",null,[t("The model uses its parameters to "),e("strong",null,"predict the most likely next token"),t(", one-by-one.")]),e("li",null,[t("Tokens are "),e("strong",null,"decoded back into text"),t(".")]),e("li",null,"It stops when it decides itâ€™s finished or reaches a token limit.")],-1)])),_:1,__:[0]},16))}};export{C as default};
